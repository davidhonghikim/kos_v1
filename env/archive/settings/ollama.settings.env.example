# Ollama Service Advanced Settings

# Default models (from ai-Q)
KOS_OLLAMA_DEFAULT_MODELS=gemma3:2b,llama3.2:3b
KOS_OLLAMA_OPTIONAL_MODELS=codellama:7b,qwen2.5:7b

# Model recommendations for different use cases:
# - Function Calling: llama3.2:3b (default), qwen2.5:7b (optional), codellama:7b (optional)
# - Code Generation: codellama:7b (optional), llama3.2:3b (default)
# - General Tasks: gemma3:2b (default), qwen2.5:7b (optional)
# - Fast Response: gemma3:2b (default), llama3.2:3b (default)
# - High Quality: qwen2.5:7b (optional), codellama:7b (optional)

# Server configuration
KOS_OLLAMA_HOST=0.0.0.0
KOS_OLLAMA_ORIGINS=*
KOS_OLLAMA_MODELS=/root/.ollama/models 